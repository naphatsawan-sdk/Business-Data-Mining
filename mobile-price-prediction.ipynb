{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f6743f1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:46.140677Z",
     "iopub.status.busy": "2022-11-23T14:55:46.139698Z",
     "iopub.status.idle": "2022-11-23T14:55:46.159366Z",
     "shell.execute_reply": "2022-11-23T14:55:46.158393Z"
    },
    "papermill": {
     "duration": 0.031869,
     "end_time": "2022-11-23T14:55:46.162432",
     "exception": false,
     "start_time": "2022-11-23T14:55:46.130563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mobile-price-classification/train.csv\n",
      "/kaggle/input/mobile-price-classification/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc81b46",
   "metadata": {
    "papermill": {
     "duration": 0.005978,
     "end_time": "2022-11-23T14:55:46.175333",
     "exception": false,
     "start_time": "2022-11-23T14:55:46.169355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1> Mobile Price Classification </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c3cfac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:46.189933Z",
     "iopub.status.busy": "2022-11-23T14:55:46.188831Z",
     "iopub.status.idle": "2022-11-23T14:55:46.193508Z",
     "shell.execute_reply": "2022-11-23T14:55:46.192704Z"
    },
    "papermill": {
     "duration": 0.014433,
     "end_time": "2022-11-23T14:55:46.195820",
     "exception": false,
     "start_time": "2022-11-23T14:55:46.181387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b95dbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:46.210715Z",
     "iopub.status.busy": "2022-11-23T14:55:46.210204Z",
     "iopub.status.idle": "2022-11-23T14:55:46.237441Z",
     "shell.execute_reply": "2022-11-23T14:55:46.236265Z"
    },
    "papermill": {
     "duration": 0.037678,
     "end_time": "2022-11-23T14:55:46.240302",
     "exception": false,
     "start_time": "2022-11-23T14:55:46.202624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/mobile-price-classification/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c9de7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:46.255023Z",
     "iopub.status.busy": "2022-11-23T14:55:46.253869Z",
     "iopub.status.idle": "2022-11-23T14:55:46.298247Z",
     "shell.execute_reply": "2022-11-23T14:55:46.296774Z"
    },
    "papermill": {
     "duration": 0.05426,
     "end_time": "2022-11-23T14:55:46.300779",
     "exception": false,
     "start_time": "2022-11-23T14:55:46.246519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>794</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1222</td>\n",
       "      <td>1890</td>\n",
       "      <td>668</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.2</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>915</td>\n",
       "      <td>1965</td>\n",
       "      <td>2032</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1911</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>868</td>\n",
       "      <td>1632</td>\n",
       "      <td>3057</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0.1</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>670</td>\n",
       "      <td>869</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>483</td>\n",
       "      <td>754</td>\n",
       "      <td>3919</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
       "0               842     0          2.2         0   1       0           7   \n",
       "1              1021     1          0.5         1   0       1          53   \n",
       "2               563     1          0.5         1   2       1          41   \n",
       "3               615     1          2.5         0   0       0          10   \n",
       "4              1821     1          1.2         0  13       1          44   \n",
       "...             ...   ...          ...       ...  ..     ...         ...   \n",
       "1995            794     1          0.5         1   0       1           2   \n",
       "1996           1965     1          2.6         1   0       0          39   \n",
       "1997           1911     0          0.9         1   1       1          36   \n",
       "1998           1512     0          0.9         0   4       1          46   \n",
       "1999            510     1          2.0         1   5       1          45   \n",
       "\n",
       "      m_dep  mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  \\\n",
       "0       0.6        188        2  ...         20       756  2549     9     7   \n",
       "1       0.7        136        3  ...        905      1988  2631    17     3   \n",
       "2       0.9        145        5  ...       1263      1716  2603    11     2   \n",
       "3       0.8        131        6  ...       1216      1786  2769    16     8   \n",
       "4       0.6        141        2  ...       1208      1212  1411     8     2   \n",
       "...     ...        ...      ...  ...        ...       ...   ...   ...   ...   \n",
       "1995    0.8        106        6  ...       1222      1890   668    13     4   \n",
       "1996    0.2        187        4  ...        915      1965  2032    11    10   \n",
       "1997    0.7        108        8  ...        868      1632  3057     9     1   \n",
       "1998    0.1        145        5  ...        336       670   869    18    10   \n",
       "1999    0.9        168        6  ...        483       754  3919    19     4   \n",
       "\n",
       "      talk_time  three_g  touch_screen  wifi  price_range  \n",
       "0            19        0             0     1            1  \n",
       "1             7        1             1     0            2  \n",
       "2             9        1             1     0            2  \n",
       "3            11        1             0     0            2  \n",
       "4            15        1             1     0            1  \n",
       "...         ...      ...           ...   ...          ...  \n",
       "1995         19        1             1     0            0  \n",
       "1996         16        1             1     1            2  \n",
       "1997          5        1             1     0            3  \n",
       "1998         19        1             1     1            0  \n",
       "1999          2        1             1     1            3  \n",
       "\n",
       "[2000 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "312fa07d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:46.316415Z",
     "iopub.status.busy": "2022-11-23T14:55:46.315263Z",
     "iopub.status.idle": "2022-11-23T14:55:46.326579Z",
     "shell.execute_reply": "2022-11-23T14:55:46.325398Z"
    },
    "papermill": {
     "duration": 0.021589,
     "end_time": "2022-11-23T14:55:46.328951",
     "exception": false,
     "start_time": "2022-11-23T14:55:46.307362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "battery_power    0\n",
       "blue             0\n",
       "clock_speed      0\n",
       "dual_sim         0\n",
       "fc               0\n",
       "four_g           0\n",
       "int_memory       0\n",
       "m_dep            0\n",
       "mobile_wt        0\n",
       "n_cores          0\n",
       "pc               0\n",
       "px_height        0\n",
       "px_width         0\n",
       "ram              0\n",
       "sc_h             0\n",
       "sc_w             0\n",
       "talk_time        0\n",
       "three_g          0\n",
       "touch_screen     0\n",
       "wifi             0\n",
       "price_range      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84395f28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:46.344156Z",
     "iopub.status.busy": "2022-11-23T14:55:46.343687Z",
     "iopub.status.idle": "2022-11-23T14:55:46.369039Z",
     "shell.execute_reply": "2022-11-23T14:55:46.367392Z"
    },
    "papermill": {
     "duration": 0.037134,
     "end_time": "2022-11-23T14:55:46.372845",
     "exception": false,
     "start_time": "2022-11-23T14:55:46.335711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   battery_power  2000 non-null   int64  \n",
      " 1   blue           2000 non-null   int64  \n",
      " 2   clock_speed    2000 non-null   float64\n",
      " 3   dual_sim       2000 non-null   int64  \n",
      " 4   fc             2000 non-null   int64  \n",
      " 5   four_g         2000 non-null   int64  \n",
      " 6   int_memory     2000 non-null   int64  \n",
      " 7   m_dep          2000 non-null   float64\n",
      " 8   mobile_wt      2000 non-null   int64  \n",
      " 9   n_cores        2000 non-null   int64  \n",
      " 10  pc             2000 non-null   int64  \n",
      " 11  px_height      2000 non-null   int64  \n",
      " 12  px_width       2000 non-null   int64  \n",
      " 13  ram            2000 non-null   int64  \n",
      " 14  sc_h           2000 non-null   int64  \n",
      " 15  sc_w           2000 non-null   int64  \n",
      " 16  talk_time      2000 non-null   int64  \n",
      " 17  three_g        2000 non-null   int64  \n",
      " 18  touch_screen   2000 non-null   int64  \n",
      " 19  wifi           2000 non-null   int64  \n",
      " 20  price_range    2000 non-null   int64  \n",
      "dtypes: float64(2), int64(19)\n",
      "memory usage: 328.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89659ccd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:46.390976Z",
     "iopub.status.busy": "2022-11-23T14:55:46.390577Z",
     "iopub.status.idle": "2022-11-23T14:55:46.467068Z",
     "shell.execute_reply": "2022-11-23T14:55:46.465934Z"
    },
    "papermill": {
     "duration": 0.088685,
     "end_time": "2022-11-23T14:55:46.469477",
     "exception": false,
     "start_time": "2022-11-23T14:55:46.380792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.0000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1238.518500</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>1.522250</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>4.309500</td>\n",
       "      <td>0.521500</td>\n",
       "      <td>32.046500</td>\n",
       "      <td>0.501750</td>\n",
       "      <td>140.249000</td>\n",
       "      <td>4.520500</td>\n",
       "      <td>...</td>\n",
       "      <td>645.108000</td>\n",
       "      <td>1251.515500</td>\n",
       "      <td>2124.213000</td>\n",
       "      <td>12.306500</td>\n",
       "      <td>5.767000</td>\n",
       "      <td>11.011000</td>\n",
       "      <td>0.761500</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>0.507000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>439.418206</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.816004</td>\n",
       "      <td>0.500035</td>\n",
       "      <td>4.341444</td>\n",
       "      <td>0.499662</td>\n",
       "      <td>18.145715</td>\n",
       "      <td>0.288416</td>\n",
       "      <td>35.399655</td>\n",
       "      <td>2.287837</td>\n",
       "      <td>...</td>\n",
       "      <td>443.780811</td>\n",
       "      <td>432.199447</td>\n",
       "      <td>1084.732044</td>\n",
       "      <td>4.213245</td>\n",
       "      <td>4.356398</td>\n",
       "      <td>5.463955</td>\n",
       "      <td>0.426273</td>\n",
       "      <td>0.500116</td>\n",
       "      <td>0.500076</td>\n",
       "      <td>1.118314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>501.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>851.750000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>282.750000</td>\n",
       "      <td>874.750000</td>\n",
       "      <td>1207.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1226.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1247.000000</td>\n",
       "      <td>2146.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1615.250000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>947.250000</td>\n",
       "      <td>1633.000000</td>\n",
       "      <td>3064.500000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1998.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1960.000000</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>3998.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       battery_power       blue  clock_speed     dual_sim           fc  \\\n",
       "count    2000.000000  2000.0000  2000.000000  2000.000000  2000.000000   \n",
       "mean     1238.518500     0.4950     1.522250     0.509500     4.309500   \n",
       "std       439.418206     0.5001     0.816004     0.500035     4.341444   \n",
       "min       501.000000     0.0000     0.500000     0.000000     0.000000   \n",
       "25%       851.750000     0.0000     0.700000     0.000000     1.000000   \n",
       "50%      1226.000000     0.0000     1.500000     1.000000     3.000000   \n",
       "75%      1615.250000     1.0000     2.200000     1.000000     7.000000   \n",
       "max      1998.000000     1.0000     3.000000     1.000000    19.000000   \n",
       "\n",
       "            four_g   int_memory        m_dep    mobile_wt      n_cores  ...  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000  ...   \n",
       "mean      0.521500    32.046500     0.501750   140.249000     4.520500  ...   \n",
       "std       0.499662    18.145715     0.288416    35.399655     2.287837  ...   \n",
       "min       0.000000     2.000000     0.100000    80.000000     1.000000  ...   \n",
       "25%       0.000000    16.000000     0.200000   109.000000     3.000000  ...   \n",
       "50%       1.000000    32.000000     0.500000   141.000000     4.000000  ...   \n",
       "75%       1.000000    48.000000     0.800000   170.000000     7.000000  ...   \n",
       "max       1.000000    64.000000     1.000000   200.000000     8.000000  ...   \n",
       "\n",
       "         px_height     px_width          ram         sc_h         sc_w  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean    645.108000  1251.515500  2124.213000    12.306500     5.767000   \n",
       "std     443.780811   432.199447  1084.732044     4.213245     4.356398   \n",
       "min       0.000000   500.000000   256.000000     5.000000     0.000000   \n",
       "25%     282.750000   874.750000  1207.500000     9.000000     2.000000   \n",
       "50%     564.000000  1247.000000  2146.500000    12.000000     5.000000   \n",
       "75%     947.250000  1633.000000  3064.500000    16.000000     9.000000   \n",
       "max    1960.000000  1998.000000  3998.000000    19.000000    18.000000   \n",
       "\n",
       "         talk_time      three_g  touch_screen         wifi  price_range  \n",
       "count  2000.000000  2000.000000   2000.000000  2000.000000  2000.000000  \n",
       "mean     11.011000     0.761500      0.503000     0.507000     1.500000  \n",
       "std       5.463955     0.426273      0.500116     0.500076     1.118314  \n",
       "min       2.000000     0.000000      0.000000     0.000000     0.000000  \n",
       "25%       6.000000     1.000000      0.000000     0.000000     0.750000  \n",
       "50%      11.000000     1.000000      1.000000     1.000000     1.500000  \n",
       "75%      16.000000     1.000000      1.000000     1.000000     2.250000  \n",
       "max      20.000000     1.000000      1.000000     1.000000     3.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7b60e25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:46.486229Z",
     "iopub.status.busy": "2022-11-23T14:55:46.485754Z",
     "iopub.status.idle": "2022-11-23T14:55:46.492719Z",
     "shell.execute_reply": "2022-11-23T14:55:46.491652Z"
    },
    "papermill": {
     "duration": 0.01853,
     "end_time": "2022-11-23T14:55:46.495290",
     "exception": false,
     "start_time": "2022-11-23T14:55:46.476760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n",
       "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
       "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n",
       "       'touch_screen', 'wifi', 'price_range'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3409a89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:46.512307Z",
     "iopub.status.busy": "2022-11-23T14:55:46.511873Z",
     "iopub.status.idle": "2022-11-23T14:55:46.518229Z",
     "shell.execute_reply": "2022-11-23T14:55:46.517074Z"
    },
    "papermill": {
     "duration": 0.017652,
     "end_time": "2022-11-23T14:55:46.520744",
     "exception": false,
     "start_time": "2022-11-23T14:55:46.503092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xall = df.drop('price_range',axis=1)\n",
    "yall = df['price_range']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae82e68",
   "metadata": {
    "papermill": {
     "duration": 0.006912,
     "end_time": "2022-11-23T14:55:46.535291",
     "exception": false,
     "start_time": "2022-11-23T14:55:46.528379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1> Hold-Out Validation </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d98dd520",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:46.553053Z",
     "iopub.status.busy": "2022-11-23T14:55:46.551823Z",
     "iopub.status.idle": "2022-11-23T14:55:47.515477Z",
     "shell.execute_reply": "2022-11-23T14:55:47.514376Z"
    },
    "papermill": {
     "duration": 0.975547,
     "end_time": "2022-11-23T14:55:47.518303",
     "exception": false,
     "start_time": "2022-11-23T14:55:46.542756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, Xtmp, y, ytmp = train_test_split(Xall, yall, test_size=0.4, random_state=0)\n",
    "Xv, Xt, yv, yt = train_test_split(Xtmp, ytmp, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77101b7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:47.535927Z",
     "iopub.status.busy": "2022-11-23T14:55:47.534768Z",
     "iopub.status.idle": "2022-11-23T14:55:47.549384Z",
     "shell.execute_reply": "2022-11-23T14:55:47.548268Z"
    },
    "papermill": {
     "duration": 0.026035,
     "end_time": "2022-11-23T14:55:47.552006",
     "exception": false,
     "start_time": "2022-11-23T14:55:47.525971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scl = MinMaxScaler().fit(X)\n",
    "X = scl.transform(X)\n",
    "Xv = scl.transform(Xv)\n",
    "Xt = scl.transform(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75428a13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:47.569530Z",
     "iopub.status.busy": "2022-11-23T14:55:47.568444Z",
     "iopub.status.idle": "2022-11-23T14:55:49.348661Z",
     "shell.execute_reply": "2022-11-23T14:55:49.347588Z"
    },
    "papermill": {
     "duration": 1.792035,
     "end_time": "2022-11-23T14:55:49.351406",
     "exception": false,
     "start_time": "2022-11-23T14:55:47.559371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "class MLP(torch.nn.Module):  \n",
    " def __init__(self, n_inputs, num_classes, dropout):  \n",
    "    super(MLP, self).__init__()  \n",
    "    self.hidden1 = torch.nn.Linear(n_inputs, 30) \n",
    "    self.act1 = torch.nn.ReLU() \n",
    "    self.hidden2 = torch.nn.Linear(30, 20) \n",
    "    self.act2 = torch.nn.ReLU() \n",
    "    self.output = torch.nn.Linear(20, num_classes) \n",
    "    self.dropout = torch.nn.Dropout(p=dropout) \n",
    " \n",
    " def forward(self, X): \n",
    "    X = self.hidden1(X)\n",
    "    X = self.act1(X)\n",
    "    X = self.hidden2(X)\n",
    "    X = self.act2(X)\n",
    "    X = self.dropout(X)\n",
    "    X = self.output(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da91ea71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:49.368139Z",
     "iopub.status.busy": "2022-11-23T14:55:49.367528Z",
     "iopub.status.idle": "2022-11-23T14:55:49.375564Z",
     "shell.execute_reply": "2022-11-23T14:55:49.374367Z"
    },
    "papermill": {
     "duration": 0.019121,
     "end_time": "2022-11-23T14:55:49.378072",
     "exception": false,
     "start_time": "2022-11-23T14:55:49.358951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76887108, 0.        , 0.04      , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.19505678, 1.        , 0.92      , ..., 1.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.84502338, 1.        , 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.46025384, 0.        , 0.6       , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.46092184, 0.        , 0.76      , ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.13694055, 0.        , 0.        , ..., 1.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a3738f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:49.394713Z",
     "iopub.status.busy": "2022-11-23T14:55:49.394335Z",
     "iopub.status.idle": "2022-11-23T14:55:49.402320Z",
     "shell.execute_reply": "2022-11-23T14:55:49.401161Z"
    },
    "papermill": {
     "duration": 0.019275,
     "end_time": "2022-11-23T14:55:49.404796",
     "exception": false,
     "start_time": "2022-11-23T14:55:49.385521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891     3\n",
       "1796    1\n",
       "1868    3\n",
       "1042    2\n",
       "996     2\n",
       "       ..\n",
       "835     3\n",
       "1216    1\n",
       "1653    3\n",
       "559     0\n",
       "684     1\n",
       "Name: price_range, Length: 1200, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e5da227",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:49.422072Z",
     "iopub.status.busy": "2022-11-23T14:55:49.421595Z",
     "iopub.status.idle": "2022-11-23T14:55:49.431721Z",
     "shell.execute_reply": "2022-11-23T14:55:49.430589Z"
    },
    "papermill": {
     "duration": 0.021537,
     "end_time": "2022-11-23T14:55:49.434097",
     "exception": false,
     "start_time": "2022-11-23T14:55:49.412560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset #เหมือนตัวเก็บข้อมูล ข้อมูลต้องเป็น float32 เท่านั้น และทำนายต้องเป็น int64 เท่านั้น\n",
    "X = torch.from_numpy(X.astype(np.float32))   #ค่า x เป็น numpy อยู่แล้ว\n",
    "y = torch.from_numpy(y.values.astype(np.int64)) #เปลี่ยนให้เป็น numpy array และเป็น int64\n",
    "\n",
    "Xv = torch.from_numpy(Xv.astype(np.float32))\n",
    "yv = torch.from_numpy(yv.values.astype(np.int64))\n",
    "\n",
    "Xt = torch.from_numpy(Xt.astype(np.float32))\n",
    "yt = torch.from_numpy(yt.values.astype(np.int64)) #บอกว่า true ก็เทรนสุ่ม 32 ตัวและเทรนไปเรื่อยๆ false โหลดทั้งหมดเข้าไปให้ทำนายเลย\n",
    "\n",
    "train_dl = DataLoader(TensorDataset(X, y), batch_size=32, shuffle=True) #dataloader โหลดข้อมูลของเราเข้าไปใน deep learning เข้าไปเทรนทีละ 32 ตัวจนครบข้อมูลทั้งหมด\n",
    "val_dl = DataLoader(TensorDataset(Xv, yv), batch_size=32, shuffle=False)\n",
    "test_dl = DataLoader(TensorDataset(Xt, yt), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85ee1f9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:49.450924Z",
     "iopub.status.busy": "2022-11-23T14:55:49.450492Z",
     "iopub.status.idle": "2022-11-23T14:55:49.457461Z",
     "shell.execute_reply": "2022-11-23T14:55:49.456606Z"
    },
    "papermill": {
     "duration": 0.017744,
     "end_time": "2022-11-23T14:55:49.459499",
     "exception": false,
     "start_time": "2022-11-23T14:55:49.441755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f69fbbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:49.476779Z",
     "iopub.status.busy": "2022-11-23T14:55:49.476345Z",
     "iopub.status.idle": "2022-11-23T14:55:59.746462Z",
     "shell.execute_reply": "2022-11-23T14:55:59.744961Z"
    },
    "papermill": {
     "duration": 10.282188,
     "end_time": "2022-11-23T14:55:59.749438",
     "exception": false,
     "start_time": "2022-11-23T14:55:49.467250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 1.3905864483431767,Val loss 1.3766303887734046, Val Acc0.3028846\n",
      "Train loss 1.3772640416496678,Val loss 1.3687632450690637, Val Acc0.31971154\n",
      "Train loss 1.3726655119343807,Val loss 1.3525804097835834, Val Acc0.38942307\n",
      "Train loss 1.3417078852653503,Val loss 1.3121878000406118, Val Acc0.43028846\n",
      "Train loss 1.2933613657951355,Val loss 1.2392708980120146, Val Acc0.6081731\n",
      "Train loss 1.2056731550317061,Val loss 1.116332274216872, Val Acc0.6370192\n",
      "Train loss 1.0951612356461977,Val loss 0.9880989927511948, Val Acc0.68509614\n",
      "Train loss 0.9937082654551456,Val loss 0.8880357192112849, Val Acc0.68509614\n",
      "Train loss 0.9109644513381155,Val loss 0.8171243438353906, Val Acc0.68990386\n",
      "Train loss 0.8440022405825163,Val loss 0.7517840357927176, Val Acc0.7379808\n",
      "Train loss 0.7879112472659663,Val loss 0.6845797850535467, Val Acc0.80528843\n",
      "Train loss 0.750150054693222,Val loss 0.6404573413041922, Val Acc0.81971157\n",
      "Train loss 0.7147175779468135,Val loss 0.6086486577987671, Val Acc0.81971157\n",
      "Train loss 0.685104112876089,Val loss 0.5648022385743948, Val Acc0.8389423\n",
      "Train loss 0.6485300267997541,Val loss 0.5393644502529731, Val Acc0.8317308\n",
      "Train loss 0.6223056222263136,Val loss 0.5073445645662454, Val Acc0.85096157\n",
      "Train loss 0.6071673592454508,Val loss 0.4960338450395144, Val Acc0.8485577\n",
      "Train loss 0.565825987019037,Val loss 0.45980504842904896, Val Acc0.87259614\n",
      "Train loss 0.5642061853095105,Val loss 0.440070030780939, Val Acc0.86538464\n",
      "Train loss 0.5481915858231092,Val loss 0.42306663669072664, Val Acc0.8894231\n",
      "Train loss 0.5196939581318906,Val loss 0.4043603791640355, Val Acc0.88221157\n",
      "Train loss 0.5024276187545375,Val loss 0.3864283378307636, Val Acc0.8918269\n",
      "Train loss 0.5065749068009225,Val loss 0.3700142273536095, Val Acc0.9110577\n",
      "Train loss 0.4785041236563733,Val loss 0.3599112767439622, Val Acc0.91586536\n",
      "Train loss 0.48683596284765945,Val loss 0.35751442267344546, Val Acc0.8942308\n",
      "Train loss 0.45399804883881617,Val loss 0.34300513107043046, Val Acc0.8942308\n",
      "Train loss 0.4381339824513385,Val loss 0.319627970457077, Val Acc0.91586536\n",
      "Train loss 0.43745046854019165,Val loss 0.31390734246143925, Val Acc0.90384614\n",
      "Train loss 0.45172207841747686,Val loss 0.3188593261517011, Val Acc0.89663464\n",
      "Train loss 0.4055116827550687,Val loss 0.3009034853715163, Val Acc0.9326923\n",
      "Train loss 0.4111847242242412,Val loss 0.2850158466742589, Val Acc0.93509614\n",
      "Train loss 0.38820935785770416,Val loss 0.28124860616830677, Val Acc0.90384614\n",
      "Train loss 0.38526820626698044,Val loss 0.2679823419222465, Val Acc0.9326923\n",
      "Train loss 0.38594657417974976,Val loss 0.26925987692979664, Val Acc0.9375\n",
      "Train loss 0.3888768004743676,Val loss 0.25703081030112046, Val Acc0.9326923\n",
      "Train loss 0.36969569952864395,Val loss 0.24652960094121787, Val Acc0.93509614\n",
      "Train loss 0.34870080336144094,Val loss 0.23651048655693346, Val Acc0.93028843\n",
      "Train loss 0.3430667558782979,Val loss 0.24184676890189832, Val Acc0.9326923\n",
      "Train loss 0.3640927852768647,Val loss 0.24086689490538377, Val Acc0.93990386\n",
      "Train loss 0.34998464584350586,Val loss 0.2269293230313521, Val Acc0.93990386\n",
      "Train loss 0.337219271220659,Val loss 0.2259725401034722, Val Acc0.92788464\n",
      "Train loss 0.3617413738056233,Val loss 0.2116576026265438, Val Acc0.93990386\n",
      "Train loss 0.3615435024625377,Val loss 0.22684784004321465, Val Acc0.92788464\n",
      "Train loss 0.33215397714,Val loss 0.21166404852500328, Val Acc0.94711536\n",
      "Train loss 0.33025623701120677,Val loss 0.2079545150582607, Val Acc0.9423077\n",
      "Train loss 0.31782636360118266,Val loss 0.20131272478745535, Val Acc0.9543269\n",
      "Train loss 0.33511495825491455,Val loss 0.20778938210927522, Val Acc0.9375\n",
      "Train loss 0.3168166522916995,Val loss 0.21477977874187323, Val Acc0.9230769\n",
      "Train loss 0.3058317005634308,Val loss 0.1938412791261306, Val Acc0.9495192\n",
      "Train loss 0.3030716055317929,Val loss 0.19168310096630684, Val Acc0.9543269\n",
      "Train loss 0.315400325938275,Val loss 0.19598649270259416, Val Acc0.9423077\n",
      "Train loss 0.29879191909965713,Val loss 0.20924859780531663, Val Acc0.9230769\n",
      "Train loss 0.2962508032980718,Val loss 0.2064454028239617, Val Acc0.93028843\n",
      "Train loss 0.28527747447553436,Val loss 0.18123474144018614, Val Acc0.9423077\n",
      "Train loss 0.2915355837658832,Val loss 0.18817647088032502, Val Acc0.9326923\n",
      "Train loss 0.29471822161423533,Val loss 0.1831949198475251, Val Acc0.9519231\n",
      "Train loss 0.28196931238237183,Val loss 0.17426088337714857, Val Acc0.9375\n",
      "Train loss 0.2951717074764402,Val loss 0.17365043323773605, Val Acc0.94471157\n",
      "Train loss 0.28099088880576584,Val loss 0.18717767928655332, Val Acc0.92788464\n",
      "Train loss 0.27090755222659363,Val loss 0.18553707576715028, Val Acc0.9230769\n",
      "Train loss 0.2639496585256175,Val loss 0.16403761506080627, Val Acc0.93509614\n",
      "Train loss 0.25600466739974526,Val loss 0.16280771906559283, Val Acc0.9567308\n",
      "Train loss 0.28270011944206136,Val loss 0.16803175268264917, Val Acc0.9326923\n",
      "Train loss 0.26610687041753217,Val loss 0.1596174595447687, Val Acc0.9567308\n",
      "Train loss 0.2583055849138059,Val loss 0.15321737298598656, Val Acc0.95913464\n",
      "Train loss 0.25995997025778417,Val loss 0.16820392814966348, Val Acc0.9423077\n",
      "Train loss 0.2434864244178722,Val loss 0.15158885029646066, Val Acc0.96153843\n",
      "Train loss 0.272779076507217,Val loss 0.1630142520253475, Val Acc0.9519231\n",
      "Train loss 0.2720744927462779,Val loss 0.15728778907885918, Val Acc0.9543269\n",
      "Train loss 0.24363514349648827,Val loss 0.14851502501047575, Val Acc0.95913464\n",
      "Train loss 0.251365479277937,Val loss 0.1506013423204422, Val Acc0.95913464\n",
      "Train loss 0.25122952147534017,Val loss 0.15128921774717477, Val Acc0.9567308\n",
      "Train loss 0.26195414403551504,Val loss 0.1466954711538095, Val Acc0.96153843\n",
      "Train loss 0.2311908179207852,Val loss 0.13870582242424673, Val Acc0.9639423\n",
      "Train loss 0.23627961074051104,Val loss 0.150821019250613, Val Acc0.9495192\n",
      "Train loss 0.23005275624363045,Val loss 0.14086514768692163, Val Acc0.9519231\n",
      "Train loss 0.23836735459534744,Val loss 0.15247258801872915, Val Acc0.94711536\n",
      "Train loss 0.23591909655614904,Val loss 0.14394956483290747, Val Acc0.9543269\n",
      "Train loss 0.23146800971344897,Val loss 0.14111763066970384, Val Acc0.9567308\n",
      "Train loss 0.24737097185693288,Val loss 0.1398044927762105, Val Acc0.9567308\n",
      "Train loss 0.25925388677339806,Val loss 0.1375770574578872, Val Acc0.95913464\n",
      "Train loss 0.2199569611172927,Val loss 0.14750690930164778, Val Acc0.9495192\n",
      "Train loss 0.2149205717601274,Val loss 0.15626246768694657, Val Acc0.93990386\n",
      "Train loss 0.21926128785861165,Val loss 0.14349468568196663, Val Acc0.93509614\n",
      "Train loss 0.22546780619182086,Val loss 0.1339279651068724, Val Acc0.95913464\n",
      "Train loss 0.2455145279435735,Val loss 0.18223674967885017, Val Acc0.9182692\n",
      "Train loss 0.24095820302241727,Val loss 0.13455183861347345, Val Acc0.9543269\n",
      "Train loss 0.20447267572346486,Val loss 0.13306883722543716, Val Acc0.95913464\n",
      "Train loss 0.21989689492865613,Val loss 0.13716149215514845, Val Acc0.9519231\n",
      "Train loss 0.20704011148528048,Val loss 0.12642759170669776, Val Acc0.96875\n",
      "Train loss 0.21665386522286817,Val loss 0.13581395951601175, Val Acc0.9519231\n",
      "Train loss 0.22035805704562286,Val loss 0.13255712647850698, Val Acc0.9543269\n",
      "Train loss 0.2243681624531746,Val loss 0.13327005763466543, Val Acc0.94471157\n",
      "Train loss 0.23048437876920952,Val loss 0.13728702813386917, Val Acc0.9519231\n",
      "Train loss 0.22293214421523244,Val loss 0.12731603131844446, Val Acc0.96875\n",
      "Train loss 0.24519128077908567,Val loss 0.1353627136693551, Val Acc0.9543269\n",
      "Train loss 0.21928485973100914,Val loss 0.14204423129558563, Val Acc0.94711536\n",
      "Train loss 0.19512261175795606,Val loss 0.12169090973643157, Val Acc0.96875\n",
      "Train loss 0.22328489822776695,Val loss 0.139603545745978, Val Acc0.94471157\n",
      "Train loss 0.19986557391913315,Val loss 0.12663882254407957, Val Acc0.9567308\n",
      "Train loss 0.21035559044072502,Val loss 0.12856185264312303, Val Acc0.9519231\n",
      "Train loss 0.21902879151074509,Val loss 0.12255143517485032, Val Acc0.96634614\n",
      "Train loss 0.20498359752328774,Val loss 0.13983177279050535, Val Acc0.9423077\n",
      "Train loss 0.21482051458013685,Val loss 0.13783810860835588, Val Acc0.9519231\n",
      "Train loss 0.20304659714824275,Val loss 0.12164379054537186, Val Acc0.97115386\n",
      "Train loss 0.19803533350166522,Val loss 0.12407396705104755, Val Acc0.9639423\n",
      "Train loss 0.19584499711268827,Val loss 0.12006610116133323, Val Acc0.9567308\n",
      "Train loss 0.19068190102514468,Val loss 0.11342968247257747, Val Acc0.96634614\n",
      "Train loss 0.2241888780538973,Val loss 0.15374447892491633, Val Acc0.94711536\n",
      "Train loss 0.18900399537462936,Val loss 0.1594850876583503, Val Acc0.9375\n",
      "Train loss 0.21893780570673316,Val loss 0.13364933230555975, Val Acc0.94711536\n",
      "Train loss 0.1918948557423918,Val loss 0.115539433577886, Val Acc0.97115386\n",
      "Train loss 0.1858712136745453,Val loss 0.12371464732747811, Val Acc0.9543269\n",
      "Train loss 0.20155307905454384,Val loss 0.11531400350997081, Val Acc0.96153843\n",
      "Train loss 0.19331488542650876,Val loss 0.12064847522057019, Val Acc0.9495192\n",
      "Train loss 0.20674885711387583,Val loss 0.11616201885044575, Val Acc0.96153843\n",
      "Train loss 0.20159071272141055,Val loss 0.13410404324531555, Val Acc0.94711536\n",
      "Train loss 0.1908956593588779,Val loss 0.11134977380816753, Val Acc0.97115386\n",
      "Train loss 0.1994534074083755,Val loss 0.11972444160626484, Val Acc0.96153843\n",
      "Train loss 0.1786911180733066,Val loss 0.11302524031354831, Val Acc0.97115386\n",
      "Train loss 0.17855633559979892,Val loss 0.11603845440997528, Val Acc0.9639423\n",
      "Train loss 0.18731005332971873,Val loss 0.11652845445160682, Val Acc0.97115386\n",
      "Train loss 0.18689277709314697,Val loss 0.11158076988962981, Val Acc0.9639423\n",
      "Train loss 0.18079907780415133,Val loss 0.1267072084144904, Val Acc0.9495192\n",
      "Train loss 0.16645928364443152,Val loss 0.11720268342357415, Val Acc0.9567308\n",
      "Train loss 0.1844281313058577,Val loss 0.10841798925629029, Val Acc0.97115386\n",
      "Train loss 0.19424690090511976,Val loss 0.1072582731453272, Val Acc0.9735577\n",
      "Train loss 0.17248661267129997,Val loss 0.1159803901727383, Val Acc0.96153843\n",
      "Train loss 0.19704645832902506,Val loss 0.11815758106800225, Val Acc0.9543269\n",
      "Train loss 0.18444770839261382,Val loss 0.16201963204030806, Val Acc0.93509614\n",
      "Train loss 0.15923892863486944,Val loss 0.11914894887461112, Val Acc0.9639423\n",
      "Train loss 0.19501319449198873,Val loss 0.12229141507011193, Val Acc0.9567308\n",
      "Train loss 0.16078695399980797,Val loss 0.11880062119318889, Val Acc0.95913464\n",
      "Train loss 0.16578352725819537,Val loss 0.11479895533277439, Val Acc0.9519231\n",
      "Train loss 0.1725161134412414,Val loss 0.13078667896871382, Val Acc0.9519231\n",
      "Train loss 0.16811513116485194,Val loss 0.10181636019394948, Val Acc0.97115386\n",
      "Train loss 0.1787532588565036,Val loss 0.1281729033933236, Val Acc0.9495192\n",
      "Train loss 0.17121313296650587,Val loss 0.12938292152606523, Val Acc0.9495192\n",
      "Train loss 0.16918193882233218,Val loss 0.10948670325944057, Val Acc0.97115386\n",
      "Train loss 0.18145300095018588,Val loss 0.12229771897769891, Val Acc0.95913464\n",
      "Train loss 0.17169797773423948,Val loss 0.1222268519206689, Val Acc0.9567308\n",
      "Train loss 0.18384386746114806,Val loss 0.16151822730898857, Val Acc0.9326923\n",
      "Train loss 0.16745275121770406,Val loss 0.14134659360234553, Val Acc0.9423077\n",
      "Train loss 0.173551524842256,Val loss 0.11311375679304966, Val Acc0.9639423\n",
      "Train loss 0.15159939445163073,Val loss 0.12693209831531233, Val Acc0.9495192\n",
      "Train loss 0.14750440222652336,Val loss 0.11894862095897014, Val Acc0.9567308\n",
      "Train loss 0.15894894115626812,Val loss 0.11314940065718614, Val Acc0.96875\n",
      "Train loss 0.16143875471071192,Val loss 0.11899312685888547, Val Acc0.9567308\n",
      "Train loss 0.15184682921359413,Val loss 0.10177784570707725, Val Acc0.96875\n",
      "Train loss 0.17135272743670563,Val loss 0.11078045101693043, Val Acc0.96875\n",
      "Train loss 0.1722755879163742,Val loss 0.1064345189012014, Val Acc0.96634614\n",
      "Train loss 0.17122424903668856,Val loss 0.1352479294515573, Val Acc0.9423077\n",
      "Train loss 0.17298721267204537,Val loss 0.11932562406246479, Val Acc0.95913464\n",
      "Train loss 0.1372702362898149,Val loss 0.14310880793401828, Val Acc0.9423077\n",
      "Train loss 0.17500473019715987,Val loss 0.17439176371464363, Val Acc0.9254808\n",
      "Train loss 0.16754879724038274,Val loss 0.11487666374215713, Val Acc0.9543269\n",
      "Train loss 0.15508856173408658,Val loss 0.1390398802379003, Val Acc0.9495192\n",
      "Train loss 0.14770984561427644,Val loss 0.13614688369517142, Val Acc0.94471157\n",
      "Train loss 0.15312687787962587,Val loss 0.14557930798484728, Val Acc0.93990386\n",
      "Train loss 0.17005511726203718,Val loss 0.12475172430276871, Val Acc0.9519231\n",
      "Train loss 0.14580305420646542,Val loss 0.12800742413562077, Val Acc0.9543269\n",
      "Train loss 0.14708143825593747,Val loss 0.12034107042619815, Val Acc0.9495192\n",
      "Train loss 0.1493124073665393,Val loss 0.1226221864613203, Val Acc0.95913464\n",
      "Train loss 0.14633155143574664,Val loss 0.13309115114120337, Val Acc0.9375\n",
      "Train loss 0.16204312777048663,Val loss 0.11765547669850863, Val Acc0.9543269\n",
      "Train loss 0.16944437454405584,Val loss 0.15856588660524443, Val Acc0.9375\n",
      "Train loss 0.1928922537910311,Val loss 0.18501929523280033, Val Acc0.9326923\n",
      "Train loss 0.16442407599013104,Val loss 0.14447975531220436, Val Acc0.9423077\n",
      "Train loss 0.13107313117698619,Val loss 0.12236916560393113, Val Acc0.95913464\n",
      "Train loss 0.15405844632340104,Val loss 0.12678366369352892, Val Acc0.9495192\n",
      "Train loss 0.15404239787082924,Val loss 0.11037277759840855, Val Acc0.9639423\n",
      "Train loss 0.16277216129789226,Val loss 0.1433318781738098, Val Acc0.9423077\n",
      "Train loss 0.13706890375990616,Val loss 0.13510222102587038, Val Acc0.93990386\n",
      "Train loss 0.12866997150214096,Val loss 0.12770192310787165, Val Acc0.9495192\n",
      "Train loss 0.17101667282220565,Val loss 0.12142797129658553, Val Acc0.9543269\n",
      "Train loss 0.15115226315040337,Val loss 0.12335025361524178, Val Acc0.95913464\n",
      "Train loss 0.16241672840949736,Val loss 0.2134420248464896, Val Acc0.93028843\n",
      "Train loss 0.15952629203859128,Val loss 0.1220801819402438, Val Acc0.9543269\n",
      "Train loss 0.15110723674297333,Val loss 0.12445765776702991, Val Acc0.9567308\n",
      "Train loss 0.14416539159260297,Val loss 0.12715669721364975, Val Acc0.9519231\n",
      "Train loss 0.1411830774067264,Val loss 0.11510576580006343, Val Acc0.95913464\n",
      "Train loss 0.14601306666276956,Val loss 0.11343604469528565, Val Acc0.95913464\n",
      "Train loss 0.16370494369613497,Val loss 0.11512289740718328, Val Acc0.9543269\n",
      "Train loss 0.15520263502472326,Val loss 0.11736547402464427, Val Acc0.9567308\n",
      "Train loss 0.17184087898778289,Val loss 0.12760716103590453, Val Acc0.9567308\n",
      "Train loss 0.1750735589548161,Val loss 0.12872395764749783, Val Acc0.96153843\n",
      "Train loss 0.15236921137885043,Val loss 0.17910738189059955, Val Acc0.9423077\n",
      "Train loss 0.15547123982718117,Val loss 0.17307839986796564, Val Acc0.94471157\n",
      "Train loss 0.12618567902398736,Val loss 0.124795035387461, Val Acc0.95913464\n",
      "Train loss 0.15458590194190802,Val loss 0.14043200402878797, Val Acc0.94711536\n",
      "Train loss 0.1375672557440243,Val loss 0.1373176696495368, Val Acc0.95913464\n",
      "Train loss 0.15521507063194326,Val loss 0.12798374189207187, Val Acc0.9567308\n",
      "Train loss 0.12712802414439225,Val loss 0.12507740795039213, Val Acc0.94471157\n",
      "Train loss 0.17275302268956838,Val loss 0.14202412418448007, Val Acc0.9495192\n",
      "Train loss 0.1450993347128755,Val loss 0.19033603513470063, Val Acc0.9375\n",
      "Train loss 0.1530235441107499,Val loss 0.1456898720218585, Val Acc0.9423077\n",
      "Train loss 0.1402603726049787,Val loss 0.12528231940590417, Val Acc0.9567308\n",
      "Train loss 0.1325579562077397,Val loss 0.1266584682923097, Val Acc0.9495192\n",
      "Train loss 0.1534048205143527,Val loss 0.1376937643553202, Val Acc0.94711536\n",
      "Train loss 0.145660518619575,Val loss 0.11945924678674111, Val Acc0.96153843\n"
     ]
    }
   ],
   "source": [
    "n_train, n_feat = X.shape\n",
    "model = MLP(n_feat, 4, 0.5)                                   # 0.5 คือค่า dropout กัน overfiting\n",
    "loss = torch.nn.CrossEntropyLoss()                            # ประกาศไว้ว่าจะหาความต่างระหว่าง output กับค่าโมเดล\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)  # จัดการเรื่องปรับจูนโมเดลต่างๆ optim.Adam เก่งที่สุดในการปรับค่าโมเดล lr(learning) คือความเร็วในการเรียนรู้ ปรับได้ตามใจ 0.1 - 0.000000001 เปลี่ยนแล้วดุว่า validation แม่นขึ้นไหม\n",
    "for epoch in range(200):                                      # 20 รอบ พอไหมขึ้นอยู่กับ lr เรียน 100 รอบอาจจะเอ๋อนะคับ หมายถึงผมอะ\n",
    "    model.train()                                             # Model in training mode เตรียมเรียนรู้\n",
    "    tr_loss = []                                              # อยากเอาไว้เก็บค่า loss ที่เกิดขึ้นในแต่ละรอบ\n",
    "    for i, (inputs, targets) in enumerate(train_dl): \n",
    "        optimizer.zero_grad()                                 # Clear gradients ค่าที่ต้องจูน ปรับให้เป็น 0 ก่อน \n",
    "        output = model(inputs)                                # Use forward pass เอา input เข้าไป เพื่อหา output\n",
    "        l= loss(output, targets)                              # Calculate loss\n",
    "        l.backward()                                          # Calculate gradients คำนวณว่าจะปรับอะไรเท่าไหร่ดี\n",
    "        optimizer.step()                                      # Update model ปรับให้ค่าดีขึ้น\n",
    "        tr_loss.append(l.item())                              # วนไปเรียนรู้เรื่อยๆ\n",
    "\n",
    "        \n",
    "#Validation\n",
    "\n",
    "    model.eval() # Model in evaluation mode\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    for i, (inputs, targets) in enumerate(val_dl):\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs) \n",
    "        l= loss(output, targets)\n",
    "        yp = torch.argmax(output, dim=1).flatten() ##\n",
    "        val_acc.append(sum(yp==targets) / len(yp))\n",
    "        val_loss.append(l.item())\n",
    " \n",
    "    print(\"Train loss \"+str(np.mean(tr_loss))+\",Val loss \"+str(np.mean(val_loss)) + \", Val Acc\" + str(np.mean(val_acc))) #มาหาค่าเฉลี่ย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b816754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:59.774247Z",
     "iopub.status.busy": "2022-11-23T14:55:59.773832Z",
     "iopub.status.idle": "2022-11-23T14:55:59.783491Z",
     "shell.execute_reply": "2022-11-23T14:55:59.782372Z"
    },
    "papermill": {
     "duration": 0.024609,
     "end_time": "2022-11-23T14:55:59.785989",
     "exception": false,
     "start_time": "2022-11-23T14:55:59.761380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  -8.7076,    6.0595,   -4.8808,  -44.1942],\n",
       "        [  22.4561,   13.1294,  -28.3669, -113.7383],\n",
       "        [  15.7327,   10.5210,  -19.1701,  -85.7944],\n",
       "        [-103.8163,    2.8705,   11.6997,   15.4350],\n",
       "        [ -55.8289,    2.8543,    7.0775,   -7.3977],\n",
       "        [ -46.8361,    3.0779,    6.3208,  -13.8710],\n",
       "        [ -49.1176,    2.9440,    6.4836,  -11.2981],\n",
       "        [-101.6085,    2.8036,   11.4576,   15.1199],\n",
       "        [  -8.3015,    6.4861,   -5.0891,  -48.2773],\n",
       "        [  18.0321,   11.3052,  -21.6968,  -96.1022],\n",
       "        [  21.1376,   12.0585,  -26.7406, -106.0964],\n",
       "        [ -54.6555,    2.3119,    6.7064,   -2.3840],\n",
       "        [  12.6952,    9.1878,  -14.6947,  -73.4482],\n",
       "        [ -62.3673,    2.2442,    7.4224,    2.1613],\n",
       "        [ -98.5441,    2.7003,   11.1128,   14.6776],\n",
       "        [ -46.9764,    2.9608,    6.2784,  -12.6035]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7328189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:59.809651Z",
     "iopub.status.busy": "2022-11-23T14:55:59.808553Z",
     "iopub.status.idle": "2022-11-23T14:55:59.816806Z",
     "shell.execute_reply": "2022-11-23T14:55:59.815797Z"
    },
    "papermill": {
     "duration": 0.022452,
     "end_time": "2022-11-23T14:55:59.818981",
     "exception": false,
     "start_time": "2022-11-23T14:55:59.796529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 3, 2, 2, 2, 3, 1, 0, 0, 2, 0, 2, 3, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d6eda05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:59.843998Z",
     "iopub.status.busy": "2022-11-23T14:55:59.843341Z",
     "iopub.status.idle": "2022-11-23T14:55:59.859848Z",
     "shell.execute_reply": "2022-11-23T14:55:59.858693Z"
    },
    "papermill": {
     "duration": 0.03169,
     "end_time": "2022-11-23T14:55:59.862332",
     "exception": false,
     "start_time": "2022-11-23T14:55:59.830642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval() # Model in evaluation mode\n",
    "ts_loss = []\n",
    "yp = []\n",
    "for i, (inputs, targets) in enumerate(val_dl):\n",
    "    with torch.no_grad():\n",
    "            output = model(inputs) \n",
    "    pred = torch.argmax(output, dim=1).flatten() \n",
    "    yp = list(pred.cpu().numpy()) if len(yp) == 0 else yp + list(pred.cpu().numpy()) \n",
    "sum(yp==yv.cpu().numpy())/len(yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94fd8182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-23T14:55:59.885636Z",
     "iopub.status.busy": "2022-11-23T14:55:59.885250Z",
     "iopub.status.idle": "2022-11-23T14:55:59.903043Z",
     "shell.execute_reply": "2022-11-23T14:55:59.902036Z"
    },
    "papermill": {
     "duration": 0.032193,
     "end_time": "2022-11-23T14:55:59.905329",
     "exception": false,
     "start_time": "2022-11-23T14:55:59.873136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9425"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval() # Model in evaluation mode\n",
    "ts_loss = []\n",
    "yp = []\n",
    "for i, (inputs, targets) in enumerate(test_dl):\n",
    "    with torch.no_grad():\n",
    "         output = model(inputs)\n",
    "    pred = torch.argmax(output, dim=1).flatten()\n",
    "    yp = list(pred.cpu().numpy()) if len(yp) == 0 else yp + list(pred.cpu().numpy()) \n",
    "sum(yp==yt.cpu().numpy())/len(yt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23.339614,
   "end_time": "2022-11-23T14:56:00.839427",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-23T14:55:37.499813",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
